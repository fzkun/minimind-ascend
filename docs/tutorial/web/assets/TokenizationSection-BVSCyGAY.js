import{r as i,j as e}from"./index-DB782DBc.js";import{C as f,S as j}from"./SourcePanel-BwVAQ71f.js";import{t as x}from"./utils-ZSIfeTeC.js";import"./constants-BXPCUJh7.js";function v(){const s="学习人工智能",l=[];let t=s.split("");l.push(t.slice());const c=[[["人","工"],"人工"],[["智","能"],"智能"],[["人工","智","能"],null],[["人工","智能"],"人工智能"],[["学","习"],"学习"],[["学习","人工智能"],null]];for(const[a,r]of c){if(!r)continue;const d=[];let o=0;for(;o<t.length;)o<t.length-1&&t[o]===a[0]&&t[o+1]===a[1]?(d.push(r),o+=2):(d.push(t[o]),o++);t=d,l.push(t.slice())}return l}const p=v(),k={你:340,好:590,我:280,是:460,的:350,了:370,不:410,在:430,有:450,这:470,人:310,大:480,中:300,上:490,一:260,个:500,到:510,来:520,时:530,会:540,说:550,他:560,她:570,地:580,出:600,就:610,也:620,和:630,对:640,能:650,都:660,学:670,习:680,工:690,智:700,机:710,器:720,语:730,言:740,模:750,型:760,世:770,界:780,想:790,要:800,生:810,活:820,做:830,可:840,以:850,吗:860,什:870,么:880,怎:890,样:900,很:910,多:920,最:930,小:940,天:950,年:960,月:970,日:980,"。":16,"，":14,"？":33,"！":3,"、":100,"“":4,"”":101,"（":10,"）":11,"\n":201,Mini:1100,Mind:1200,mind:1201,Hello:1300,World:1400,the:400,is:461,a:66,of:402,to:403,and:501,in:404,that:405,I:44,you:406,it:407," ":220,".":16,",":14,"?":33,"!":3},g={你好:1500,什么:1501,怎样:1502,可以:1503,人工:1504,智能:1505,学习:1506,语言:1507,模型:1508,世界:1509,生活:1510,MiniMind:1511,人工智能:1600};function y(s){const l=[];let t=0;for(;t<s.length;){let c=!1;for(let a=Math.min(8,s.length-t);a>0;a--){const r=s.substring(t,t+a);if(g[r]!==void 0){l.push({text:r,id:g[r]}),t+=a,c=!0;break}if(a<=4&&k[r]!==void 0){l.push({text:r,id:k[r]}),t+=a,c=!0;break}}c||(l.push({text:s[t],id:s.charCodeAt(t)%256+3}),t++)}return l}function E(){const[s,l]=i.useState(0),t=i.useRef(null),[c,a]=i.useState(!1),[r,d]=i.useState("你好，我是MiniMind。"),o=i.useCallback(()=>{t.current&&(clearInterval(t.current),t.current=null),a(!1)},[]);i.useEffect(()=>()=>{t.current&&clearInterval(t.current)},[]);const _=i.useCallback(()=>{if(t.current){o();return}a(!0),t.current=setInterval(()=>{l(n=>n<p.length-1?n+1:(o(),n))},800)},[o]),b=i.useCallback(()=>{o(),l(0)},[o]),h=p[s],m=y(r);return e.jsxs(e.Fragment,{children:[e.jsx("h2",{children:"1. 分词 (Tokenization)"}),e.jsxs("p",{className:"desc",children:["LLM 处理文本的第一步：把原始字符串拆成 token 列表，每个 token 对应词表中的一个整数 ID。 MiniMind 使用 BPE 分词器，",e.jsx("code",{children:"vocab_size=6400"}),"，调用方式类似 ",e.jsx("code",{children:'tokenizer.encode("你好")'})," → ",e.jsx("code",{children:"[868, 1059]"}),"。",e.jsx("br",{}),e.jsxs("small",{style:{color:"var(--fg2)"},children:["关联源码：",e.jsx("code",{children:"trainer/train_tokenizer.py:18"})," 训练分词器 | ",e.jsx("code",{children:"model/tokenizer.json"})," 词表文件"]})]}),e.jsxs(f,{title:"BPE 合并动画",children:[e.jsx("p",{style:{marginBottom:10,fontSize:"0.9rem",color:"var(--fg2)"},children:'BPE（Byte Pair Encoding）从字符级开始，统计所有相邻 token 对的出现频率，将最高频的一对合并为新 token，反复迭代直到达到目标词表大小。 下方以"学习人工智能"为例，点击按钮逐步观看合并过程：'}),e.jsx("div",{style:{minHeight:50,padding:10,background:"var(--bg)",borderRadius:"var(--radius)",border:"1px solid var(--border)",marginBottom:10,display:"flex",flexWrap:"wrap",gap:2,alignItems:"center"},children:h.map((n,u)=>e.jsx("span",{className:"token-box",style:{background:x(u),color:"#fff",fontSize:"1rem",padding:"6px 12px"},children:n},`${s}-${u}`))}),e.jsxs("div",{style:{display:"flex",gap:8,alignItems:"center",flexWrap:"wrap"},children:[e.jsx("button",{className:"btn",onClick:()=>l(n=>Math.max(0,n-1)),children:"◀ 上一步"}),e.jsx("button",{className:"btn primary",onClick:()=>l(n=>Math.min(p.length-1,n+1)),children:"下一步 ▶"}),e.jsx("button",{className:"btn",onClick:_,children:c?"⏸ 暂停":"▶ 自动播放"}),e.jsx("button",{className:"btn",onClick:b,children:"重置"}),e.jsxs("span",{style:{fontSize:"0.8rem",color:"var(--fg3)"},children:["步骤 ",s,"/",p.length-1,s>0?` — 合并后 ${h.length} 个 token`:` — ${h.length} 个字符`]})]}),s>0&&e.jsxs("p",{style:{marginTop:8,fontSize:"0.85rem",color:"var(--fg2)",fontStyle:"italic"},children:[s===1&&'第 1 步：发现"人"+"工"是最高频相邻对，合并为"人工"。这一步减少了 1 个 token。',s===2&&'第 2 步：发现"智"+"能"是下一个最高频对，合并为"智能"。',s===3&&'第 3 步：发现"人工"+"智能"可以继续合并，得到"人工智能"。多次合并可以形成更长的子词。',s===4&&'第 4 步：最终"学"+"习"也被合并为"学习"，6 个字符被压缩为 2 个 token。BPE 的压缩率取决于训练语料中的词频统计。']}),e.jsx(j,{title:"对照源码：dataset/lm_dataset.py:31-49 (PretrainDataset)",code:`class PretrainDataset(Dataset):
    """预训练数据集：将原始文本转为 token 序列"""
    def __init__(self, data_path, tokenizer, max_length=512):
        self.tokenizer = tokenizer           # BPE 分词器，词表大小 6400
        self.max_length = max_length         # 每条样本最大长度（含特殊 token）
        # 使用 HuggingFace datasets 加载 JSONL 文件，每行一个 {"text": "..."} 对象
        self.samples = load_dataset('json', data_files=data_path, split='train')

    def __getitem__(self, index):
        sample = self.samples[index]
        # 调用分词器进行 BPE 编码
        # add_special_tokens=False: 不自动加 BOS/EOS，后面手动添加
        # truncation=True: 超长文本截断到 max_length-2（预留 BOS+EOS 位置）
        tokens = self.tokenizer(
            str(sample['text']),
            add_special_tokens=False,
            max_length=self.max_length - 2,
            truncation=True
        ).input_ids
        # 手动拼接: [BOS] + 正文 tokens + [EOS]
        tokens = [self.tokenizer.bos_token_id] + tokens + [self.tokenizer.eos_token_id]
        # 右侧填充 PAD 到固定长度 max_length，使 batch 内所有样本等长
        input_ids = tokens + [self.tokenizer.pad_token_id] * (self.max_length - len(tokens))
        # labels 与 input_ids 相同，但 PAD 位置标记为 -100
        # PyTorch CrossEntropyLoss 会自动忽略 -100 标签，不对 PAD 计算损失
        labels = input_ids.clone()
        labels[input_ids == self.tokenizer.pad_token_id] = -100
        return input_ids, labels`})]}),e.jsxs(f,{title:"实时分词演示",children:[e.jsx("p",{style:{marginBottom:8,fontSize:"0.9rem",color:"var(--fg2)"},children:'在下方输入文本，实时查看分词结果。本演示使用内嵌的高频 token 子集（约 120 个词元）进行最长前缀匹配模拟。 每个彩色方块代表一个 token，悬停可查看对应的 ID。分词器会优先匹配最长的复合 token（如"人工智能"→1600）， 未知字符回退到 Unicode 字节编码。'}),e.jsx("textarea",{value:r,onChange:n=>d(n.target.value),placeholder:"输入中文或英文文本，例如：你好世界 Hello World"}),e.jsxs("div",{style:{marginTop:10},children:[e.jsx("div",{className:"label",children:"Token 序列："}),e.jsx("div",{style:{minHeight:36,padding:8,background:"var(--bg)",borderRadius:"var(--radius)",border:"1px solid var(--border)"},children:m.map((n,u)=>e.jsx("span",{className:"token-box",style:{background:x(u),color:"#fff"},title:`ID: ${n.id}`,children:n.text===" "?"␣":n.text===`
`?"↵":n.text},u))})]}),e.jsxs("div",{style:{marginTop:8},children:[e.jsx("div",{className:"label",children:"Token IDs："}),e.jsxs("div",{style:{fontFamily:"monospace",fontSize:"0.85rem",color:"var(--accent)",wordBreak:"break-all"},children:["[",m.map(n=>n.id).join(", "),"]"]})]})]})]})}export{E as default};
